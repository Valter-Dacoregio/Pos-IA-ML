{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregas as bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetar o gerador de números aleatórios\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o número de atributos (features)\n",
    "number_of_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados (conjunto de dados de avaliações de filmes)\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(num_words=number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter o formato dos dados para uma matriz de features\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode='binary')\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar a rede neural\n",
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar a primeira camada, com a função de ativação ReLU\n",
    "network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona a segunda camada, com a função de ativação ReLU\n",
    "network.add(layers.Dense(units=16, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar a tereira camada, com a função de ativação sigmoid\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar a rede neural\n",
    "network.compile(loss='binary_crossentropy', # Função de perda\n",
    "                optimizer='rmsprop', # Otimizador\n",
    "                metrics=['accuracy']) # Métrica de desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7348 - loss: 0.5195 - val_accuracy: 0.8516 - val_loss: 0.3495\n",
      "Epoch 2/3\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8659 - loss: 0.3218 - val_accuracy: 0.8594 - val_loss: 0.3305\n",
      "Epoch 3/3\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.8727 - loss: 0.3076 - val_accuracy: 0.8616 - val_loss: 0.3253\n"
     ]
    }
   ],
   "source": [
    "# Treinar a rede neural\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target\n",
    "                      epochs=3, # Número de épocas\n",
    "                      verbose=1, # Imprimir informações a cada época\n",
    "                      batch_size=100, # Número de observações por lote\n",
    "                      validation_data=(features_test, target_test)) # Dados de validação"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
