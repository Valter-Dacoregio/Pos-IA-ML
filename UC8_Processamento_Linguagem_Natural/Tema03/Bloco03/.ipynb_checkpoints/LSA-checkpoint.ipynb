{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b8fd79c-7af4-4664-beae-5d46c85858dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b5dc57c-ab12-4982-81d3-fa7264754912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(path, nome_arq):\n",
    "    lista_documentos = []\n",
    "    titulos = []\n",
    "    with open (os.path.join(path, nome_arq), \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            text = line.strip()\n",
    "            lista_documentos.append(text)\n",
    "        titulos.append(text[0:min(len(text), 100)])\n",
    "        return lista_documentos, titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4517f2e1-af5a-4483-af62-ce04882cde37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_dados(doc_set):\n",
    "    # inicializar o tokenizer regex\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # cria uma lista de stopwords em inglês\n",
    "    stopword_ing = set(stopwords.words('english'))\n",
    "    # Crie p_stemmer da classe PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    # Lista de documentos tokenizados\n",
    "    texts = []\n",
    "    # Percorrer a lista de documentos\n",
    "    for i in doc_set:\n",
    "        # limpar e tokenizar a string de documentos\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        # remove stop words dos tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in stopword_ing]\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        # adicionaa tokens a lista\n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "671a1746-3462-4e9b-bac0-d2c0c1506971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_corpus(documento_preparado):\n",
    "    # Criar o dicionário de termos do nosso corpus, onde cada termo único é atribuído a um índice.\n",
    "    dictionary = corpora.Dictionary(documento_preparado)\n",
    "    dictionary = corpora.Dictionary(documento_preparado)\n",
    "    # Convertendo a lista de documentos (corpus) em Document Term Matrix usando o dicionário preparado\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in documento_preparado]\n",
    "    # gera modelo LDA\n",
    "    return dictionary, doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebcd7a17-df2d-40d9-899f-3c88f430f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_modelo_LSA(documento_preparado, qtd_topicos, words):\n",
    "    dictionary, doc_term_matrix = preparar_corpus(documento_preparado)\n",
    "    # gera o modelo LSA\n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=qtd_topicos, id2word = dictionary) # train model\n",
    "    print(lsamodel.print_topics(num_topics=qtd_topicos, num_words=words))\n",
    "    return lsamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24771b95-1365-4be2-80f6-f4225d14e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculo_coerencia(dictionary, doc_term_matrix, documento_preparado, stop, start=2, step=3):\n",
    "    valor_coerencia = []\n",
    "    model_list = []\n",
    "    for qtd_topicos in range(start, stop, step):\n",
    "        # gera modelo LSA\n",
    "        model = LsiModel(doc_term_matrix, num_topics=qtd_topicos, id2word = dictionary)\n",
    "        # modelo de treinamento\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = documento_preparado, dictionary=dictionary)\n",
    "        valor_coerencia.append(coherencemodel.get_coherence())\n",
    "    return model_list, valor_coerencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a45767bb-b6f7-4b8d-ba5c-58f6618cd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(documento_preparado, start, stop, step):\n",
    "    dictionary, doc_term_matrix = preparar_corpus(documento_preparado)\n",
    "    model_list, valor_coerencia = calculo_coerencia(dictionary, doc_term_matrix, documento_preparado, stop, start, step)\n",
    "    # mostra o gráfico\n",
    "    x = range(start, stop, step)\n",
    "    plt.plot(x, valor_coerencia)\n",
    "    plt.xlabel(\"Número de tópicos\")\n",
    "    plt.ylabel(\"Score de coerência\")\n",
    "    plt.legend((\"valor_coerencia\"), loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f13665d4-27e7-4a2b-aebe-51b00167b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '-0.395*\"point\" + -0.269*\"first\" + -0.250*\"final\" + -0.212*\"quarter\" + -0.203*\"nba\" + -0.200*\"buck\" + -0.188*\"sun\" + -0.172*\"antetokounmpo\" + -0.156*\"player\" + -0.134*\"said\"'), (1, '-0.363*\"vaccin\" + -0.328*\"mask\" + -0.289*\"school\" + -0.171*\"student\" + -0.169*\"19\" + -0.160*\"guidanc\" + -0.157*\"covid\" + -0.150*\"univers\" + -0.149*\"effect\" + -0.144*\"recommend\"'), (2, '0.313*\"everi\" + -0.299*\"point\" + 0.279*\"day\" + 0.270*\"embrac\" + 0.270*\"champion\" + 0.239*\"final\" + -0.224*\"quarter\" + 0.182*\"made\" + 0.177*\"get\" + 0.152*\"play\"'), (3, '-0.553*\"fire\" + -0.264*\"deploy\" + -0.202*\"said\" + -0.195*\"oregon\" + -0.184*\"mobil\" + -0.140*\"tuesday\" + -0.136*\"time\" + -0.135*\"season\" + -0.119*\"mani\" + -0.107*\"acr\"')]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'get_coherence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m cria_modelo_LSA(limpar_texto, qtdd_topicos, words)\n\u001b[1;32m      7\u001b[0m start,stop,step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 8\u001b[0m plot_graph(limpar_texto, start, stop, step)\n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m, in \u001b[0;36mplot_graph\u001b[0;34m(documento_preparado, start, stop, step)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_graph\u001b[39m(documento_preparado, start, stop, step):\n\u001b[1;32m      2\u001b[0m     dictionary, doc_term_matrix \u001b[38;5;241m=\u001b[39m preparar_corpus(documento_preparado)\n\u001b[0;32m----> 3\u001b[0m     model_list, valor_coerencia \u001b[38;5;241m=\u001b[39m calculo_coerencia(dictionary, doc_term_matrix, documento_preparado, stop, start, step)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# mostra o gráfico\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(start, stop, step)\n",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m, in \u001b[0;36mcalculo_coerencia\u001b[0;34m(dictionary, doc_term_matrix, documento_preparado, stop, start, step)\u001b[0m\n\u001b[1;32m      8\u001b[0m     model_list\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m      9\u001b[0m     coherencemodel \u001b[38;5;241m=\u001b[39m CoherenceModel(model \u001b[38;5;241m=\u001b[39m model, texts \u001b[38;5;241m=\u001b[39m documento_preparado, dictionary\u001b[38;5;241m=\u001b[39mdictionary), \n\u001b[0;32m---> 10\u001b[0m     valor_coerencia\u001b[38;5;241m.\u001b[39mappend(coherencemodel\u001b[38;5;241m.\u001b[39mget_coherence())\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_list, valor_coerencia\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'get_coherence'"
     ]
    }
   ],
   "source": [
    "qtdd_topicos = 4\n",
    "words = 10\n",
    "lista_documentos, titulos = carregar_dados(\"\", \"noticias.txt\")\n",
    "limpar_texto = processar_dados(lista_documentos)\n",
    "model = cria_modelo_LSA(limpar_texto, qtdd_topicos, words)\n",
    "\n",
    "start,stop,step = 2,4,1\n",
    "plot_graph(limpar_texto, start, stop, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0a83f-466f-4c63-849a-5e70c423b122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
